{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83865623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import collections\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df4201d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 0、数据处理成csv形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eb38d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['age', 'workclass', 'fnlwgt', 'education', 'educationNum', 'maritalStatus', 'occupation', 'relationship', 'race', 'sex',\n",
    "          'capitalGain', 'capitalLoss', 'hoursPerWeek', 'nativeCountry', 'income']\n",
    "df_train_set = pd.read_csv('./adult.data', names=columns)\n",
    "df_test_set = pd.read_csv('./adult.test', names=columns, skiprows=1) #第一行是非法数据\n",
    "\n",
    "df_train_set.to_csv('./train_adult.csv', index=False)\n",
    "df_test_set.to_csv('./test_adult.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8399bb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1、数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f840bf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_set = pd.read_csv('./train_adult.csv')\n",
    "df_test_set = pd.read_csv('./test_adult.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fac4abab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2、数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d138ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.1 删除对应属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac775bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_set.drop(['fnlwgt', 'educationNum'], axis=1, inplace=True)\n",
    "df_test_set.drop(['fnlwgt', 'educationNum'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2506b67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.2 重复行记录处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eac9368e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_set.drop_duplicates(inplace=True)\n",
    "df_test_set.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2b922e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.3 缺失值处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d319533f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_set.dropna(inplace=True)\n",
    "df_test_set.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbefb1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.4 异常值处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5beb63f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = ['workclass', 'education', 'maritalStatus', 'occupation', 'relationship', 'race', 'sex',\n",
    "               'nativeCountry', 'income']\n",
    "for col in new_columns:\n",
    "    df_train_set = df_train_set[~df_train_set[col].str.contains(r'\\?', regex=True)]\n",
    "    df_test_set = df_test_set[~df_test_set[col].str.contains(r'\\?', regex=True)]\n",
    "\n",
    "df_train_set.reset_index(drop=True, inplace=True)\n",
    "df_test_set.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c073600",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.5 连续型变量处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0362dee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 25, 50, 75, 100]\n",
    "df_train_set['age'] = pd.cut(df_train_set['age'], bins, labels=False)\n",
    "df_test_set['age'] = pd.cut(df_test_set['age'], bins, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97feb6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.6 离散型变量处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec4bab13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个通用的映射函数，处理未知类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a03b310e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mapping(column_values):\n",
    "    unique_values = column_values.unique()\n",
    "    mapping = {label: idx for idx, label in enumerate(unique_values)}\n",
    "    mapping['unknown'] = len(mapping)  # 为未知类别添加一个索引\n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0c7e31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集样本数： 26904\n",
      "测试集样本数： 14130\n",
      "训练集缺失值情况：\n",
      " age              0\n",
      "workclass        0\n",
      "education        0\n",
      "maritalStatus    0\n",
      "occupation       0\n",
      "relationship     0\n",
      "race             0\n",
      "sex              0\n",
      "capitalGain      0\n",
      "capitalLoss      0\n",
      "hoursPerWeek     0\n",
      "nativeCountry    0\n",
      "income           0\n",
      "dtype: int64\n",
      "测试集缺失值情况：\n",
      " age              0\n",
      "workclass        0\n",
      "education        0\n",
      "maritalStatus    0\n",
      "occupation       0\n",
      "relationship     0\n",
      "race             0\n",
      "sex              0\n",
      "capitalGain      0\n",
      "capitalLoss      0\n",
      "hoursPerWeek     0\n",
      "nativeCountry    0\n",
      "income           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 处理训练集\n",
    "mappings = {}  # 保存所有映射，以便在测试集中使用相同的映射\n",
    "\n",
    "for col in new_columns:\n",
    "    if col == 'income':\n",
    "        continue  # income列单独处理\n",
    "    mapping = create_mapping(df_train_set[col])\n",
    "    mappings[col] = mapping\n",
    "    df_train_set[col] = df_train_set[col].map(mapping)\n",
    "\n",
    "# income编码\n",
    "income_mapping = {'<=50K': 0, '>50K': 1}\n",
    "df_train_set['income'] = df_train_set['income'].str.strip()\n",
    "df_train_set['income'] = df_train_set['income'].map(income_mapping)\n",
    "mappings['income'] = income_mapping\n",
    "\n",
    "# 处理测试集，使用与训练集相同的映射\n",
    "for col in new_columns:\n",
    "    if col == 'income':\n",
    "        continue\n",
    "    mapping = mappings[col]\n",
    "    if 'unknown' not in mapping:\n",
    "        mapping['unknown'] = len(mapping)\n",
    "    df_test_set[col] = df_test_set[col].map(lambda x: mapping.get(x, mapping['unknown']))\n",
    "\n",
    "# income编码\n",
    "df_test_set['income'] = df_test_set['income'].str.strip()\n",
    "df_test_set['income'] = df_test_set['income'].str.replace('.', '', regex=False)\n",
    "df_test_set['income'] = df_test_set['income'].map(lambda x: income_mapping.get(x, -1))\n",
    "\n",
    "# 检查数据集长度\n",
    "print(\"训练集样本数：\", len(df_train_set))\n",
    "print(\"测试集样本数：\", len(df_test_set))\n",
    "\n",
    "# 检查是否存在缺失值\n",
    "print(\"训练集缺失值情况：\\n\", df_train_set.isnull().sum())\n",
    "print(\"测试集缺失值情况：\\n\", df_test_set.isnull().sum())\n",
    "\n",
    "# 如果仍有缺失值，可以选择填充或删除\n",
    "df_train_set.fillna(-1, inplace=True)\n",
    "df_test_set.fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d744155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 构造决策树，进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79903ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gini(df):\n",
    "    labels = df['income']\n",
    "    label_counts = labels.value_counts()\n",
    "    total = len(labels)\n",
    "    gini = 1.0 - sum((count / total) ** 2 for count in label_counts)\n",
    "    return gini\n",
    "\n",
    "def split_dataset(df, index, value):\n",
    "    feature = df.columns[index]\n",
    "    left_df = df[df[feature] == value]\n",
    "    right_df = df[df[feature] != value]\n",
    "    return left_df, right_df\n",
    "\n",
    "def choose_best_feature_to_split(df):\n",
    "    base_gini = calc_gini(df)\n",
    "    best_gini = float('inf')\n",
    "    best_feature_index = -1\n",
    "    best_value = None\n",
    "    best_splits = None\n",
    "\n",
    "    num_features = len(df.columns) - 1  # Exclude the label column 'income'\n",
    "    for i in range(num_features):\n",
    "        feature = df.columns[i]\n",
    "        unique_values = df[feature].unique()\n",
    "        for value in unique_values:\n",
    "            left_df, right_df = split_dataset(df, i, value)\n",
    "            if len(left_df) == 0 or len(right_df) == 0:\n",
    "                continue  # Skip invalid splits\n",
    "\n",
    "            total_instances = len(df)\n",
    "            weight_left = len(left_df) / total_instances\n",
    "            weight_right = len(right_df) / total_instances\n",
    "            gini_left = calc_gini(left_df)\n",
    "            gini_right = calc_gini(right_df)\n",
    "            gini_split = weight_left * gini_left + weight_right * gini_right\n",
    "\n",
    "            if gini_split < best_gini:\n",
    "                best_gini = gini_split\n",
    "                best_feature_index = i\n",
    "                best_value = value\n",
    "                best_splits = (left_df, right_df)\n",
    "\n",
    "    if best_feature_index == -1:\n",
    "        # No valid split found\n",
    "        return None, None, None\n",
    "    else:\n",
    "        return (best_feature_index, best_value), best_splits, best_gini\n",
    "\n",
    "def build_decision_tree(df, columns, flags):\n",
    "    labels = df['income']\n",
    "    # Base case 1: If all labels are the same, return the label\n",
    "    if len(labels.unique()) == 1:\n",
    "        return {'label': labels.iloc[0]}\n",
    "\n",
    "    # Base case 2: If no features left to split on, return the majority label\n",
    "    if len(df.columns) == 1:  # Only the label column is left\n",
    "        majority_label = labels.value_counts().idxmax()\n",
    "        return {'label': majority_label}\n",
    "\n",
    "    # Choose the best feature to split\n",
    "    best_feature, best_splits, best_gini = choose_best_feature_to_split(df)\n",
    "\n",
    "    if best_feature is None:\n",
    "        # No valid split found, return majority label\n",
    "        majority_label = labels.value_counts().idxmax()\n",
    "        return {'label': majority_label}\n",
    "\n",
    "    feature_index, feature_value = best_feature\n",
    "    feature_name = df.columns[feature_index]\n",
    "\n",
    "    # Build subtrees\n",
    "    left_df, right_df = best_splits\n",
    "\n",
    "    left_subtree = build_decision_tree(left_df.drop(columns=[feature_name]), columns, flags)\n",
    "    right_subtree = build_decision_tree(right_df.drop(columns=[feature_name]), columns, flags)\n",
    "\n",
    "    # Return the tree\n",
    "    return {'feature_index': feature_index,\n",
    "            'feature_name': feature_name,\n",
    "            'value': feature_value,\n",
    "            'left': left_subtree,\n",
    "            'right': right_subtree}\n",
    "\n",
    "def save_decision_tree(cart):\n",
    "    np.save('cart.npy', cart)\n",
    "\n",
    "def load_decision_tree():\n",
    "    cart = np.load('cart.npy', allow_pickle=True)\n",
    "    return cart.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c73fc3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train_set.copy() #防止预处理重新来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75c305eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_train.columns.to_list()\n",
    "flags = [0 for i in range(len(columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e05a0578",
   "metadata": {},
   "outputs": [],
   "source": [
    "cart = build_decision_tree(df_train, columns, flags)\n",
    "save_decision_tree(cart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "818974ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. 评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59a39e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(cart, df_row, columns):\n",
    "    if 'label' in cart:\n",
    "        return cart['label']\n",
    "    else:\n",
    "        feature_name = cart['feature_name']\n",
    "        feature_value = cart['value']\n",
    "        if feature_name not in df_row:\n",
    "            return random.randint(0, 1)  # 如果特征缺失，随机返回一个标签\n",
    "        if df_row[feature_name] == feature_value:\n",
    "            return classify(cart['left'], df_row, columns)\n",
    "        else:\n",
    "            return classify(cart['right'], df_row, columns)\n",
    "\n",
    "def predict(cart, df, columns):\n",
    "    pred_list = []\n",
    "    for i in range(len(df)):\n",
    "        pred_label = classify(cart, df.iloc[i, :], columns)\n",
    "        pred_list.append(pred_label)\n",
    "    return pred_list\n",
    "\n",
    "def calc_acc(pred_list, test_list):\n",
    "    pred = np.array(pred_list)\n",
    "    test = np.array(test_list)\n",
    "    acc = np.sum(pred == test) / len(test)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df34cbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. 预测和评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "255d70ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集上的准确率为: 0.8167020523708421\n"
     ]
    }
   ],
   "source": [
    "# 开始预测\n",
    "columns = df_train.columns.to_list()\n",
    "cart = load_decision_tree()  # 加载模型\n",
    "test_list = df_test_set['income'].to_numpy()\n",
    "pred_list = predict(cart, df_test_set, columns)\n",
    "acc = calc_acc(pred_list, test_list)\n",
    "print(\"测试集上的准确率为:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7759198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测结果已保存到 test_predictions.csv 文件中。\n"
     ]
    }
   ],
   "source": [
    "# 将预测结果输出到新的.csv文件中\n",
    "df_test_set['prediction'] = pred_list\n",
    "df_test_set.to_csv('test_predictions.csv', index=False)\n",
    "print(\"预测结果已保存到 test_predictions.csv 文件中。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba21e84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f041d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
